# Summary RandomForest Classifier

## 1. Definition
- 기계학습의 알고리즘
    - 앙상블 ensemble 학습 방법의 일종
    - 훈련과정에서 생성된 다수의 결정 트리로부터 분류, 평균예측(회귀분석)을 반환한다.
    - 검출, 분류, 회귀 등의 문제에서 활용된다.
- 특징
    - 랜덤성에 의해 트리들이 서로 조금씩 다른 특성을 갖는다.
        - 랜덤화는 각 트리들의 훈련과정에서 진행
	- 각각의 트리를 생성할 때 랜덤 학습 데이터 추출방법인 배깅 또는 노드 최적화 방법이 자주 사용됨. 
    - 각 트리들이 예측한 결과들이 비상관관계를 갖기 때문에 결과적으로 일반화 성능을 높여준다.
    
## 2. History
- 얄리 아미트, 도널드 게먼, 틴 캄 호 등의 연구자들이 랜덤 포레스트의 구조와 모형에 관한 아이디어를 제공
- 현재의 랜덤 포레스트는 레오 브레이먼의 논문에서 비롯됨

## 3. Major concenpts

#### 1) 배깅 Bagging : Bootstrap Aggregating 
- 배깅은 여러개의 트리를 결합하여 포레스트를 구성하는 방식
- 부트스트랩 bootstrap 을 통해서 추출한 훈련 데이터로 훈련된 분류기들을 결합(aggregating) 시키는 방법
   - 부트스트랩 : 주어진 훈련데이터에서 중복을 허용하여 원래 데이터셋과 같은 크기의 데이터셋을 만드는 과정
- 배깅의 단계 :
   - bootstrap -> tree1, tree2, ..., treeM -> fitting -> aggregating ; RandomForest
   - i) 부트스트랩 방법을 통해 T 개의 훈련 데이터 셋 생성
   - ii) T 개의 기초 분류기 tree 들을 훈련
   - iii) 기초 분류기들을 하나의 분류기로 결합한다. : 평균치 또는 과반수투표 방식을 이용하여 결합
- 트리는 작은 편향과 큰 분산을 갖는다. 따라서 트리의 깊이가 깊어질 수록 훈련데이터에 대해 과적합 overfitting 하게 됨
- 부트스트랩은 트리의 편향은 유지하고 분산은 감소시키기 때문에 포레스트의 성능을 높이게 된다. 
- 한 개의 결정트리는 훈련데이터의 노이즈에 대해 매우 민감하지만, 각각의 트리들이 서로 상관화 되어 있지 않다면 여러 트리들의 평균은 노이즈에 대해 일관된(강인한) 결과를 갖는다.
- 즉 개별 트리들을 같은 데이터셋으로 훈련시킬 경우 트리들 간의 상관성은 매우 커지게 된다.
- 배깅은 개별 트리들을 서로 다른 데이터셋들로 훈련 시키기 때문에 트리들간의 비상관성을 높여준다.
